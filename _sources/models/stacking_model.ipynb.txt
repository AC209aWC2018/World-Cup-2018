{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from predict_test_data import predict_test_data\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/cleaned/train_final.csv')\n",
    "test = pd.read_csv('../data/cleaned/test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['attack_away_defence_home_diff', 'attack_home_defence_away_diff', \n",
    "           'attack_diff', 'defence_diff', 'midfield_diff', 'prestige_diff', 'growth_diff', \n",
    "           'full_age_diff', 'start_age_diff', 'value_euros_millions_diff','wage_euros_thousands_diff', \n",
    "           'goalkeeper_overall_diff', 'bup_dribbling_diff', 'bup_passing_diff', 'bup_speed_diff',\n",
    "           'cc_crossing_diff', 'cc_passing_diff', 'cc_shooting_diff', 'd_aggresion_diff', 'd_pressure_diff', \n",
    "           'd_width_diff', 'gdp_diff', 'is_home', 'raw_gdp_diff', \n",
    "          'score_past_5_games_diff', 'score_conceded_past_5_games_diff', 'prev_champ']\n",
    "\n",
    "train = train[columns + ['home_win']]\n",
    "test = test[columns + ['Group', 'home_win']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(14)\n",
    "X_train, X_valid = train_test_split(train, test_size = 0.2)\n",
    "y_train = X_train['home_win'].ravel()\n",
    "X_train = X_train.drop(['home_win'], axis = 1)\n",
    "y_valid= X_valid['home_win'].ravel()\n",
    "X_valid = X_valid.drop(['home_win'], axis = 1)\n",
    "y_test = test['home_win'].ravel()\n",
    "\n",
    "# collect group\n",
    "grp = test['Group'].ravel()\n",
    "grp_id = [0 if len(i) == 1 else 1 for i in grp]\n",
    "X_test = test.drop(['home_win', 'Group'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that most models performed similarly. Why not try stacking the models together? We will stack the logistic regression, LDA, QDA, Random Forest, and XGBoost models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_models(X_train, y_train):\n",
    "\n",
    "    lr_mod = LogisticRegressionCV(solver = 'lbfgs', \n",
    "                                  max_iter = 5000, \n",
    "                                  cv = 5, \n",
    "                                  multi_class='multinomial').fit(X_train, y_train)\n",
    "    lda_mod = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "    qda_mod = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    rf_params = {'bootstrap': [True, False],\n",
    "             'max_depth': [3, 5, 10, 20, 30, 40, None],\n",
    "             'max_features': ['auto', 'sqrt'],\n",
    "             'min_samples_leaf': [1, 2, 4, 10, 20],\n",
    "             'min_samples_split': [2, 5, 10],\n",
    "             'n_estimators': [10, 50, 100, 200, 500]}\n",
    "\n",
    "    rf_mod = RandomizedSearchCV(estimator=RandomForestClassifier(), param_distributions=rf_params,\\\n",
    "                                n_iter=50, scoring='accuracy', n_jobs=-1, cv=5, verbose=0).fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    xgb_params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "    xgb_model = RandomizedSearchCV(estimator=XGBClassifier(objective='multi:softmax', num_class = 3), param_distributions=xgb_params,\\\n",
    "                                       n_iter=50, scoring='accuracy', n_jobs=-1, cv=5, verbose=0).fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    return (lr_mod, lda_mod, qda_mod, rf_mod, xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = make_models(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_stack_model(models, X_train, y_train): \n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        predictions.append(model.predict(X_train))\n",
    "        \n",
    "    predictions = np.array(predictions).T\n",
    "    logit = LogisticRegression(C=1000).fit(predictions, y_train)\n",
    "    return logit\n",
    "    \n",
    "def stack_model_predict(models, stack_model, X, test = False):\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        if not test:\n",
    "            predictions.append(model.predict(X))        \n",
    "        else:\n",
    "            predictions.append(predict_test_data(X, model))\n",
    "    predictions = np.array(predictions).T\n",
    "    return stack_model.predict(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_kept = models\n",
    "stack_model = fit_stack_model(models_kept, X_valid, y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.609375"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, stack_model_predict(models_kept, stack_model, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
