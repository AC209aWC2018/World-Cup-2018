{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first build some basic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from predict_test_data import predict_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_team.csv')\n",
    "test = pd.read_csv('../data/test_team.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['home_win', 'attack_diff', 'bup_dribbling_diff', 'bup_passing_diff',\n",
       "       'bup_speed_diff', 'cc_crossing_diff', 'cc_passing_diff',\n",
       "       'cc_shooting_diff', 'd_aggresion_diff', 'd_pressure_diff',\n",
       "       'd_width_diff', 'defence_diff', 'full_age_diff',\n",
       "       'goalkeeeper_overall_diff', 'growth_diff', 'midfield_diff',\n",
       "       'overall_diff', 'prestige_diff', 'start_age_diff',\n",
       "       'value_euros_millions_diff', 'wage_euros_thousands_diff',\n",
       "       'attack_home_defence_away_diff', 'attack_away_defence_home_diff',\n",
       "       'cur_year_avg_weighted_diff', 'cur_year_avg_diff',\n",
       "       'last_year_avg_weighted_diff', 'last_year_avg_diff',\n",
       "       'previous_points_diff', 'rank_change_diff', 'rank_diff',\n",
       "       'three_year_ago_avg_diff', 'three_year_ago_weighted_diff',\n",
       "       'total_points_diff', 'two_year_ago_avg_diff',\n",
       "       'two_year_ago_weighted_diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['home_win', 'attack_diff', 'bup_dribbling_diff', 'bup_passing_diff',\n",
       "       'bup_speed_diff', 'cc_crossing_diff', 'cc_passing_diff',\n",
       "       'cc_shooting_diff', 'd_aggresion_diff', 'd_pressure_diff',\n",
       "       'd_width_diff', 'defence_diff', 'full_age_diff',\n",
       "       'goalkeeeper_overall_diff', 'growth_diff', 'midfield_diff',\n",
       "       'overall_diff', 'prestige_diff', 'start_age_diff',\n",
       "       'value_euros_millions_diff', 'wage_euros_thousands_diff',\n",
       "       'attack_home_defence_away_diff', 'attack_away_defence_home_diff',\n",
       "       'cur_year_avg_weighted_diff', 'cur_year_avg_diff',\n",
       "       'last_year_avg_weighted_diff', 'last_year_avg_diff',\n",
       "       'previous_points_diff', 'rank_change_diff', 'rank_diff',\n",
       "       'three_year_ago_avg_diff', 'three_year_ago_weighted_diff',\n",
       "       'total_points_diff', 'two_year_ago_avg_diff',\n",
       "       'two_year_ago_weighted_diff', 'Group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our most basic model would be to just predict the majority class every time. In this case, `home_win` = 1 is the majority class. What are is the training accuracy from just doing this \"prediction\"? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44168962350780533"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['home_win'].value_counts()[1] / len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty decent when we have 3 classes. What about the test accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.421875"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test['home_win'], np.ones(len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still decent. Any model we build should be better than this test accuracy of just guessing.\n",
    "\n",
    "Our baseline model will be pretty simple. We will utilize the differences in FIFA rankings, offense ratings, defense ratings, midfield ratings, and overall ratings. We will make a train and validation set out of the original train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['gdp_diff'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-800cea6d5565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rank_diff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'home_win'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attack_diff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'defence_diff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'midfield_diff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'overall_diff'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'gdp_diff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rank_diff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'home_win'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attack_diff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'defence_diff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'midfield_diff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'overall_diff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gdp_diff'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Group'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['gdp_diff'] not in index\""
     ]
    }
   ],
   "source": [
    "train = train[['rank_diff', 'home_win', 'attack_diff', 'defence_diff', 'midfield_diff', 'overall_diff','gdp_diff']]\n",
    "test = test[['rank_diff', 'home_win', 'attack_diff', 'defence_diff', 'midfield_diff', 'overall_diff', 'gdp_diff','Group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['gdp_diff'] = train['gdp_diff'].astype('category')\n",
    "# test['gdp_diff'] = test['gdp_diff'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank_diff        float64\n",
       "home_win           int64\n",
       "attack_diff      float64\n",
       "defence_diff     float64\n",
       "midfield_diff    float64\n",
       "overall_diff     float64\n",
       "gdp_diff         float64\n",
       "Group             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "X_train, X_validation = train_test_split(train, test_size = 0.2)\n",
    "y_train = X_train['home_win'].ravel()\n",
    "X_train = X_train.drop(['home_win'], axis = 1)\n",
    "y_validation = X_validation['home_win'].ravel()\n",
    "X_validation = X_validation.drop(['home_win'], axis = 1)\n",
    "y_test = test['home_win'].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first try out logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegressionCV(solver = 'lbfgs', max_iter = 5000, cv = 5, multi_class='multinomial').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train Score: 0.5228095582910934\n",
      "Logistic Regression Validation Score: 0.5173410404624278\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Train Score: {}\".format(lr_model.score(X_train, y_train)))\n",
    "print(\"Logistic Regression Validation Score: {}\".format(lr_model.score(X_validation, y_validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also try out Linear Discriminant Analysis. However, we need to first check whether the variances across the three outcomes are equal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_diff</th>\n",
       "      <th>attack_diff</th>\n",
       "      <th>defence_diff</th>\n",
       "      <th>midfield_diff</th>\n",
       "      <th>overall_diff</th>\n",
       "      <th>gdp_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_win</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1031.324335</td>\n",
       "      <td>41.178286</td>\n",
       "      <td>36.447164</td>\n",
       "      <td>36.358733</td>\n",
       "      <td>30.316051</td>\n",
       "      <td>0.947174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1030.878211</td>\n",
       "      <td>43.164681</td>\n",
       "      <td>38.173861</td>\n",
       "      <td>37.613713</td>\n",
       "      <td>31.811819</td>\n",
       "      <td>0.843246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100.677884</td>\n",
       "      <td>42.149203</td>\n",
       "      <td>40.387636</td>\n",
       "      <td>36.910224</td>\n",
       "      <td>32.722352</td>\n",
       "      <td>0.850783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rank_diff  attack_diff  defence_diff  midfield_diff  overall_diff  \\\n",
       "home_win                                                                        \n",
       "0         1031.324335    41.178286     36.447164      36.358733     30.316051   \n",
       "1         1030.878211    43.164681     38.173861      37.613713     31.811819   \n",
       "2         1100.677884    42.149203     40.387636      36.910224     32.722352   \n",
       "\n",
       "          gdp_diff  \n",
       "home_win            \n",
       "0         0.947174  \n",
       "1         0.843246  \n",
       "2         0.850783  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('home_win').var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, they are actually quite similar! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LinearDiscriminantAnalysis().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Train Score: 0.5213613323678494\n",
      "LDA Validation Score: 0.5144508670520231\n"
     ]
    }
   ],
   "source": [
    "print(\"LDA Train Score: {}\".format(lda_model.score(X_train, y_train)))\n",
    "print(\"LDA Validation Score: {}\".format(lda_model.score(X_validation, y_validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also try out Quadratic Discriminant Analysis, which should perform similarly to LDA in this case due to the almost equal variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_model = QuadraticDiscriminantAnalysis().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA Train Score: 0.5228095582910934\n",
      "QDA Validation Score: 0.5144508670520231\n"
     ]
    }
   ],
   "source": [
    "print(\"QDA Train Score: {}\".format(qda_model.score(X_train, y_train)))\n",
    "print(\"QDA Validation Score: {}\".format(qda_model.score(X_validation, y_validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also try out Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(min_samples_leaf = 20, n_estimators=100).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.556842867487328\n",
      "0.5404624277456648\n"
     ]
    }
   ],
   "source": [
    "print(rf_model.score(X_train, y_train))\n",
    "print(rf_model.score(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how these models perform on the actual World Cup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Score: 0.609375\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Test Score: {}\".\n",
    "                format(accuracy_score(test['home_win'], predict_test_data(test, X_train.columns, lr_model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Test Score: 0.609375\n"
     ]
    }
   ],
   "source": [
    "print(\"LDA Test Score: {}\".format(\n",
    "    accuracy_score(test['home_win'], predict_test_data(test, X_train.columns, lda_model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA Test Score: 0.609375\n"
     ]
    }
   ],
   "source": [
    "print(\"QDA Test Score: {}\".format(\n",
    "    accuracy_score(test['home_win'], predict_test_data(test, X_train.columns, qda_model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Score: 0.625\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Test Score: {}\".format(\n",
    "    accuracy_score(test['home_win'], predict_test_data(test, X_train.columns, rf_model))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impressive! We now have an idea of what our more advanced model should hope to achieve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
