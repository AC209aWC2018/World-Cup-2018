{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from predict_test_data import predict_test_data\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/cleaned/train_final.csv')\n",
    "test = pd.read_csv('../data/cleaned/test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['attack_away_defence_home_diff', 'attack_home_defence_away_diff', \n",
    "           'attack_diff', 'defence_diff', 'midfield_diff', 'prestige_diff', 'growth_diff', \n",
    "           'full_age_diff', 'start_age_diff', 'value_euros_millions_diff','wage_euros_thousands_diff', \n",
    "           'goalkeeper_overall_diff', 'bup_dribbling_diff', 'bup_passing_diff', 'bup_speed_diff',\n",
    "           'cc_crossing_diff', 'cc_passing_diff', 'cc_shooting_diff', 'd_aggresion_diff', 'd_pressure_diff', \n",
    "           'd_width_diff', 'gdp_diff', 'is_home', 'raw_gdp_diff', \n",
    "           'score_past_5_games_diff', 'score_conceded_past_5_games_diff', 'prev_champ']\n",
    "train = train[columns + ['home_win']]\n",
    "test = test[columns + ['Group', 'home_win']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(14)\n",
    "X_train, X_valid = train_test_split(train, test_size = 0.2)\n",
    "y_train = X_train['home_win'].ravel()\n",
    "X_train = X_train.drop(['home_win'], axis = 1)\n",
    "y_valid= X_valid['home_win'].ravel()\n",
    "X_valid = X_valid.drop(['home_win'], axis = 1)\n",
    "y_test = test['home_win'].ravel()\n",
    "\n",
    "# collect group\n",
    "grp = test['Group'].ravel()\n",
    "grp_id = [0 if len(i) == 1 else 1 for i in grp]\n",
    "X_test = test.drop(['home_win', 'Group'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_models(X_train, y_train):\n",
    "\n",
    "#     # scale data\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(X_train)\n",
    "#     X_train_scaled = scaler.transform(X_train)\n",
    "        \n",
    "    lr_mod = LogisticRegressionCV(solver = 'lbfgs', \n",
    "                                  max_iter = 5000, \n",
    "                                  cv = 5, \n",
    "                                  multi_class='multinomial').fit(X_train, y_train)\n",
    "    lda_mod = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "    qda_mod = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    rf_params = {'bootstrap': [True, False],\n",
    "             'max_depth': [3, 5, 10, 20, 30, 40, None],\n",
    "             'max_features': ['auto', 'sqrt'],\n",
    "             'min_samples_leaf': [1, 2, 4, 10, 20],\n",
    "             'min_samples_split': [2, 5, 10],\n",
    "             'n_estimators': [10, 50, 100, 200, 500]}\n",
    "\n",
    "    rf_mod = RandomizedSearchCV(estimator=RandomForestClassifier(), param_distributions=rf_params,\\\n",
    "                                n_iter=50, scoring='accuracy', n_jobs=-1, cv=5, verbose=1).fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    xgb_params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "    xgb_model = RandomizedSearchCV(estimator=XGBClassifier(objective='multi:softmax', num_class = 3), param_distributions=xgb_params,\\\n",
    "                                       n_iter=50, scoring='accuracy', n_jobs=-1, cv=5, verbose=1).fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "#     # PCA on data\n",
    "#     pca = PCA().fit(X_train_scaled)\n",
    "#     X_train_pca = pca.transform(X_train_scaled)\n",
    "\n",
    "#     # full components\n",
    "#     pcr_mod = LogisticRegressionCV(solver = 'lbfgs', \n",
    "#                                    max_iter = 5000, \n",
    "#                                    cv = 5, \n",
    "#                                    multi_class='multinomial').fit(X_train_pca, y_train)\n",
    "\n",
    "    \n",
    "    \n",
    "#     pca_cumvar = np.cumsum(pca.explained_variance_ratio_) \n",
    "    \n",
    "#     pca80_com = np.argmax(pca_cumvar >= 0.8)+1\n",
    "#     pca90_com = np.argmax(pca_cumvar >= 0.9)+1\n",
    "    \n",
    "#     # 80% variation\n",
    "#     pca80 = PCA(n_components=pca80_com).fit(X_train_scaled)\n",
    "#     X_train_pca80 = pca80.transform(X_train_scaled)\n",
    "\n",
    "#     # 90% variation\n",
    "#     pca90 = PCA(n_components=pca90_com).fit(X_train_scaled)\n",
    "#     X_train_pca90 = pca90.transform(X_train_scaled)\n",
    "\n",
    "#     # fit models\n",
    "#     pcr80_mod = LogisticRegressionCV(solver = 'lbfgs', \n",
    "#                                      max_iter = 5000, \n",
    "#                                      cv = 5, \n",
    "#                                      multi_class='multinomial').fit(X_train_pca80, y_train)\n",
    "#     pcr90_mod = LogisticRegressionCV(solver = 'lbfgs', \n",
    "#                                      max_iter = 5000, \n",
    "#                                      cv = 5, \n",
    "#                                      multi_class='multinomial').fit(X_train_pca90, y_train)\n",
    "\n",
    "    \n",
    "#     lb = LabelBinarizer()\n",
    "#     y_train_lb = lb.fit_transform(y_train)\n",
    "    \n",
    "#     plsda_train_score = []\n",
    "\n",
    "#     for i in np.arange(1, X_train.shape[1]):\n",
    "#         plsda_mod = PLSRegression(n_components=i, scale=False) \n",
    "#         plsda_mod.fit(X_train_scaled, y_train_lb)\n",
    "#         plsda_train_score.append(accuracy_score(y_train, np.argmax(plsda_mod.predict(X_train_scaled), axis=1) - 1))\n",
    "    \n",
    "#     plsda_best_com = np.argmax(plsda_train_score)+1\n",
    "#     plsda_best_mod = PLSRegression(n_components=plsda_best_com, scale=False) \n",
    "#     plsda_best_mod.fit(X_train_scaled, y_train_lb)\n",
    "    \n",
    "    \n",
    "    return (lr_mod, lda_mod, qda_mod, rf_mod, xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.5s\n"
     ]
    }
   ],
   "source": [
    "models = make_models(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_stack_model(models, X_train, y_train): \n",
    "#     # scale data\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(X_train)\n",
    "#     X_train_scaled = scaler.transform(X_train)\n",
    "    \n",
    "#     predictions = []\n",
    "#     for model in models:\n",
    "#         predictions.append(model.predict(X_train))\n",
    "        \n",
    "# #     # PCA on data\n",
    "# #     pca = PCA().fit(X_train_scaled)\n",
    "# #     X_train_pca = pca.transform(X_train_scaled)\n",
    "\n",
    "# #     # full components\n",
    "# #     pcr_mod = LogisticRegressionCV(solver = 'lbfgs', \n",
    "# #                                    max_iter = 5000, \n",
    "# #                                    cv = 5, \n",
    "# #                                    multi_class='multinomial').fit(X_train_pca, y_train)\n",
    "\n",
    "#     lb = LabelBinarizer()\n",
    "#     y_train_lb = lb.fit_transform(y_train)\n",
    "    \n",
    "#     plsda_train_score = []\n",
    "\n",
    "#     for i in np.arange(1, X_train.shape[1]):\n",
    "#         plsda_mod = PLSRegression(n_components=i, scale=False) \n",
    "#         plsda_mod.fit(X_train_scaled, y_train_lb)\n",
    "#         plsda_train_score.append(accuracy_score(y_train, np.argmax(plsda_mod.predict(X_train_scaled), axis=1) - 1))\n",
    "    \n",
    "#     plsda_best_com = np.argmax(plsda_train_score)+1\n",
    "#     plsda_best_mod = PLSRegression(n_components=plsda_best_com, scale=False) \n",
    "#     plsda_best_mod.fit(X_train_scaled, y_train_lb)\n",
    "        \n",
    "#     predictions.append(np.argmax(plsda_best_mod.predict(X_train_scaled), axis = 1) - 1)\n",
    "#     predictions = np.array(predictions).T\n",
    "#     logit = LogisticRegression(C=1000).fit(predictions , y_train)\n",
    "#     return {'stack_model': logit, 'plsda_model': plsda_best_mod, 'scaler': scaler}\n",
    "    \n",
    "# def stack_model_predict(models, fit_return, X):\n",
    "#     stack_model = fit_return['stack_model']\n",
    "#     predictions = []\n",
    "#     for model in models:\n",
    "#         predictions.append(model.predict(X))\n",
    "#     X_scaled = fit_return['scaler'].transform(X)\n",
    "#     predictions.append(np.argmax(fit_return['plsda_model'].predict(X_scaled), axis = 1) - 1)\n",
    "        \n",
    "#     predictions = np.array(predictions).T\n",
    "    \n",
    "#     return stack_model.predict(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_stack_model(models, X_train, y_train): \n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        predictions.append(model.predict(X_train))\n",
    "        \n",
    "    predictions = np.array(predictions).T\n",
    "    logit = LogisticRegression(C=1000).fit(predictions, y_train)\n",
    "    return logit\n",
    "    \n",
    "def stack_model_predict(models, stack_model, X, test = False):\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        if not test:\n",
    "            predictions.append(model.predict(X))        \n",
    "        else:\n",
    "            predictions.append(predict_test_data(X, model))\n",
    "    predictions = np.array(predictions).T\n",
    "    return stack_model.predict(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_kept = models[:5]\n",
    "stack_model = fit_stack_model(models_kept, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, stack_model_predict(models_kept, stack_model, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
