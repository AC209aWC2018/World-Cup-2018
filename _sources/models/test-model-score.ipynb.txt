{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from predict_test_data import predict_test_data\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/cleaned/train_final.csv')\n",
    "test = pd.read_csv('../data/cleaned/test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_models(train, test, seed=14):\n",
    "    #Same seed as baseline to ensure same train and validation sets so that comparisons are valid.\n",
    "    #10\n",
    "    np.random.seed(seed)\n",
    "    X_train, X_valid = train_test_split(train, test_size = 0.2)\n",
    "    y_train = X_train['home_win'].ravel()\n",
    "    X_train = X_train.drop(['home_win'], axis = 1)\n",
    "    y_valid= X_valid['home_win'].ravel()\n",
    "    X_valid = X_valid.drop(['home_win'], axis = 1)\n",
    "    y_test = test['home_win'].ravel()\n",
    "\n",
    "\n",
    "    # collect group\n",
    "    grp = test['Group'].ravel()\n",
    "    grp_id = [0 if len(i) == 1 else 1 for i in grp]\n",
    "    X_test = test.drop(['home_win', 'Group'], axis = 1)\n",
    "\n",
    "    # scale data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # stores the score of each model\n",
    "    score = {}\n",
    "    \n",
    "    lr_mod = LogisticRegressionCV(solver = 'lbfgs', \n",
    "                                  max_iter = 5000, \n",
    "                                  cv = 5, \n",
    "                                  multi_class='multinomial').fit(X_train, y_train)\n",
    "    score[\"Logistic Regression\"] = {}\n",
    "    score[\"Logistic Regression\"][\"model\"] = lr_mod\n",
    "    score[\"Logistic Regression\"][\"Train Score\"] = lr_mod.score(X_train, y_train)\n",
    "    score[\"Logistic Regression\"][\"Validation Score\"] = lr_mod.score(X_valid, y_valid)\n",
    "    score[\"Logistic Regression\"][\"Test Score\"] = lr_mod.score(X_test, y_test)\n",
    "\n",
    "    lda_mod = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "    \n",
    "    score[\"LDA\"] = {}\n",
    "    score[\"LDA\"][\"model\"] = lda_mod\n",
    "    score[\"LDA\"][\"Train Score\"] = lda_mod.score(X_train, y_train)\n",
    "    score[\"LDA\"][\"Validation Score\"] = lda_mod.score(X_valid, y_valid)\n",
    "    score[\"LDA\"][\"Test Score\"] = lda_mod.score(X_test, y_test)\n",
    "    \n",
    "    qda_mod = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "    \n",
    "    score[\"QDA\"] = {}\n",
    "    score[\"QDA\"]['model'] = qda_mod\n",
    "    score[\"QDA\"][\"Train Score\"] = qda_mod.score(X_train, y_train)\n",
    "    score[\"QDA\"][\"Validation Score\"] = qda_mod.score(X_valid, y_valid)\n",
    "    score[\"QDA\"][\"Test Score\"] = qda_mod.score(X_test, y_test)\n",
    "    \n",
    "    rf_params = {'bootstrap': [True, False],\n",
    "             'max_depth': [3, 5, 10, 20, 30, 40, None],\n",
    "             'max_features': ['auto', 'sqrt'],\n",
    "             'min_samples_leaf': [1, 2, 4, 10, 20],\n",
    "             'min_samples_split': [2, 5, 10],\n",
    "             'n_estimators': [10, 50, 100, 200, 500]}\n",
    "\n",
    "    rf_mod = RandomizedSearchCV(estimator=RandomForestClassifier(), param_distributions=rf_params,\\\n",
    "                                n_iter=50, scoring='accuracy', n_jobs=-1, cv=5, verbose=1).fit(X_train, y_train)\n",
    "    \n",
    "    score[\"Random Forest\"] = {}\n",
    "    score[\"Random Forest\"]['model'] = rf_mod\n",
    "    score[\"Random Forest\"][\"Train Score\"] = rf_mod.score(X_train, y_train)\n",
    "    score[\"Random Forest\"][\"Validation Score\"] = rf_mod.score(X_valid, y_valid)\n",
    "    score[\"Random Forest\"][\"Test Score\"] = rf_mod.score(X_test, y_test)\n",
    "    \n",
    "\n",
    "    xgb_params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "    xgb_model = RandomizedSearchCV(estimator=XGBClassifier(objective='multi:softmax', num_class = 3), param_distributions=xgb_params,\\\n",
    "                                       n_iter=50, scoring='accuracy', n_jobs=-1, cv=5, verbose=1).fit(X_train, y_train)\n",
    "    score[\"XGBoost\"] = {}\n",
    "    score[\"XGBoost\"]['model'] = xgb_model\n",
    "    score[\"XGBoost\"][\"Train Score\"] = xgb_model.score(X_train, y_train)\n",
    "    score[\"XGBoost\"][\"Validation Score\"] = xgb_model.score(X_valid, y_valid)\n",
    "    score[\"XGBoost\"][\"Test Score\"] = xgb_model.score(X_test, y_test)\n",
    "\n",
    "\n",
    "    \n",
    "    # PCA on data\n",
    "    pca = PCA().fit(X_train_scaled)\n",
    "    X_train_pca = pca.transform(X_train_scaled)\n",
    "    X_valid_pca = pca.transform(X_valid_scaled)\n",
    "\n",
    "    # full components\n",
    "    pcr_mod = LogisticRegressionCV(solver = 'lbfgs', \n",
    "                                   max_iter = 5000, \n",
    "                                   cv = 5, \n",
    "                                   multi_class='multinomial').fit(X_train_pca, y_train)\n",
    "    # test set\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    pcr_test_pred = [np.where(np.argsort(val) == 1)[0][0]-1 if (i==1) & (np.argmax(val) == 1)\n",
    "                     else np.argmax(val)-1 for i, val in zip(grp_id, pcr_mod.predict_proba(X_test_pca))]\n",
    "    \n",
    "    \n",
    "    score[\"pcr_full\"] = {}\n",
    "    score[\"pcr_full\"][\"model\"] = pcr_mod\n",
    "    score[\"pcr_full\"][\"Train Score\"] = pcr_mod.score(X_train_pca, y_train)\n",
    "    score[\"pcr_full\"][\"Validation Score\"] = pcr_mod.score(X_valid_pca, y_valid)\n",
    "    score[\"pcr_full\"][\"Test Score\"] = accuracy_score(y_test, pcr_test_pred)\n",
    "    \n",
    "    pca_cumvar = np.cumsum(pca.explained_variance_ratio_) \n",
    "    \n",
    "    pca80_com = np.argmax(pca_cumvar >= 0.8)+1\n",
    "    pca90_com = np.argmax(pca_cumvar >= 0.9)+1\n",
    "    \n",
    "    # 80% variation\n",
    "    pca80 = PCA(n_components=pca80_com).fit(X_train_scaled)\n",
    "    X_train_pca80 = pca80.transform(X_train_scaled)\n",
    "    X_valid_pca80 = pca80.transform(X_valid_scaled)\n",
    "\n",
    "    # 90% variation\n",
    "    pca90 = PCA(n_components=pca90_com).fit(X_train_scaled)\n",
    "    X_train_pca90 = pca90.transform(X_train_scaled)\n",
    "    X_valid_pca90 = pca90.transform(X_valid_scaled)\n",
    "\n",
    "    # fit models\n",
    "    pcr80_mod = LogisticRegressionCV(solver = 'lbfgs', \n",
    "                                     max_iter = 5000, \n",
    "                                     cv = 5, \n",
    "                                     multi_class='multinomial').fit(X_train_pca80, y_train)\n",
    "    pcr90_mod = LogisticRegressionCV(solver = 'lbfgs', \n",
    "                                     max_iter = 5000, \n",
    "                                     cv = 5, \n",
    "                                     multi_class='multinomial').fit(X_train_pca90, y_train)\n",
    "    \n",
    "    # test set\n",
    "    # 80% variation\n",
    "    X_test_pca80 = pca80.transform(X_test_scaled)\n",
    "\n",
    "    pcr80_test_pred = [np.where(np.argsort(val) == 1)[0][0]-1 if (i==1) & (np.argmax(val) == 1)\n",
    "                       else np.argmax(val)-1 for i, val in zip(grp_id, pcr80_mod.predict_proba(X_test_pca80))]\n",
    "\n",
    "    # 90% variation\n",
    "    X_test_pca90 = pca90.transform(X_test_scaled)\n",
    "\n",
    "    pcr90_test_pred = [np.where(np.argsort(val) == 1)[0][0]-1 if (i==1) & (np.argmax(val) == 1)\n",
    "                       else np.argmax(val)-1 for i, val in zip(grp_id, pcr90_mod.predict_proba(X_test_pca90))]\n",
    "    \n",
    "    # 80% variation\n",
    "    score[\"pcr_80%\"] = {}\n",
    "    score[\"pcr_80%\"][\"model\"] = pcr80_mod\n",
    "    score[\"pcr_80%\"][\"Train Score\"] = pcr80_mod.score(X_train_pca80, y_train)\n",
    "    score[\"pcr_80%\"][\"Validation Score\"] = pcr80_mod.score(X_valid_pca80, y_valid)\n",
    "    score[\"pcr_80%\"][\"Test Score\"] = accuracy_score(y_test, pcr80_test_pred)\n",
    "    \n",
    "    # 90% variation\n",
    "    score[\"pcr_90%\"] = {}\n",
    "    score[\"pcr_90%\"][\"model\"] = pcr90_mod\n",
    "    score[\"pcr_90%\"][\"Train Score\"] = pcr90_mod.score(X_train_pca90, y_train)\n",
    "    score[\"pcr_90%\"][\"Validation Score\"] = pcr90_mod.score(X_valid_pca90, y_valid)\n",
    "    score[\"pcr_90%\"][\"Test Score\"] = accuracy_score(y_test, pcr90_test_pred)\n",
    "    \n",
    "    \n",
    "    pcr_train_score = []\n",
    "    pcr_valid_score = []\n",
    "    pcr_test_score = []\n",
    "\n",
    "    for i in np.arange(1, X_train.shape[1]):\n",
    "        pca_cv = PCA(n_components=i).fit(X_train_scaled)\n",
    "        X_train_pca_cv = pca_cv.transform(X_train_scaled)\n",
    "        X_valid_pca_cv = pca_cv.transform(X_valid_scaled)\n",
    "        X_test_pca_cv = pca_cv.transform(X_test_scaled)\n",
    "    \n",
    "        pcr_cv_mod = LogisticRegressionCV(solver = 'lbfgs', \n",
    "                                          max_iter = 5000, \n",
    "                                          cv = 5, \n",
    "                                          multi_class='multinomial').fit(X_train_pca_cv, y_train)\n",
    "    \n",
    "        pcr_train_score.append(pcr_cv_mod.score(X_train_pca_cv, y_train))\n",
    "        pcr_valid_score.append(pcr_cv_mod.score(X_valid_pca_cv, y_valid))\n",
    "    \n",
    "        pcr_test_score.append(accuracy_score(y_test,\n",
    "                                             [np.where(np.argsort(val) == 1)[0][0]-1 if (i==1) & (np.argmax(val) == 1)\n",
    "                                              else np.argmax(val)-1 for i, val in zip(grp_id, pcr_cv_mod.predict_proba(X_test_pca_cv))]))\n",
    "        \n",
    "    pca_best_com = np.argmax(pcr_valid_score)+1\n",
    "        \n",
    "    pca_best = PCA(n_components=pca_best_com).fit(X_train_scaled)\n",
    "    X_train_pca_best = pca_best.transform(X_train_scaled)\n",
    "    X_valid_pca_best = pca_best.transform(X_valid_scaled)\n",
    "\n",
    "    # fit models\n",
    "    pcr_best_mod = LogisticRegressionCV(solver = 'lbfgs', \n",
    "                                        max_iter = 5000, \n",
    "                                        cv = 5, \n",
    "                                        multi_class='multinomial').fit(X_train_pca_best, y_train)\n",
    "    \n",
    "    # test set\n",
    "    X_test_pca_best = pca_best.transform(X_test_scaled)\n",
    "\n",
    "    pcr_best_test_pred = [np.where(np.argsort(val) == 1)[0][0]-1 if (i==1) & (np.argmax(val) == 1)\n",
    "                          else np.argmax(val)-1 for i, val in zip(grp_id, pcr_best_mod.predict_proba(X_test_pca_best))]\n",
    "\n",
    "    score[\"pcr_best\"] = {}\n",
    "    score[\"pcr_best\"][\"model\"] = pcr_best_mod\n",
    "    score[\"pcr_best\"][\"Train Score\"] = pcr_best_mod.score(X_train_pca_best, y_train)\n",
    "    score[\"pcr_best\"][\"Validation Score\"] = pcr_best_mod.score(X_valid_pca_best, y_valid)\n",
    "    score[\"pcr_best\"][\"Test Score\"] = accuracy_score(y_test, pcr_best_test_pred)\n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    y_train_lb = lb.fit_transform(y_train)\n",
    "    \n",
    "    plsda_train_score = []\n",
    "    plsda_valid_score = []\n",
    "\n",
    "    for i in np.arange(1, X_train.shape[1]):\n",
    "        plsda_mod = PLSRegression(n_components=i, scale=False) \n",
    "        plsda_mod.fit(X_train_scaled, y_train_lb)\n",
    "\n",
    "        plsda_train_score.append(accuracy_score(y_train, np.argmax(plsda_mod.predict(X_train_scaled), axis=1) - 1))\n",
    "        plsda_valid_score.append(accuracy_score(y_valid, np.argmax(plsda_mod.predict(X_valid_scaled), axis=1) - 1))\n",
    "    \n",
    "    plsda_best_com = np.argmax(plsda_valid_score)+1\n",
    "    \n",
    "    # check test accuracy\n",
    "    plsda_best_mod = PLSRegression(n_components=plsda_best_com, scale=False) \n",
    "    plsda_best_mod.fit(X_train_scaled, y_train_lb)\n",
    "\n",
    "    plsda_best_test_pred = [np.where(np.argsort(val) == 1)[0][0]-1 if (i==1) & (np.argmax(val) == 1) \n",
    "                            else np.argmax(val)-1 for i, val in zip(grp_id, plsda_best_mod.predict(X_test_scaled))]\n",
    "    \n",
    "    score[\"plsda_best\"] = {}\n",
    "    score[\"plsda_best\"][\"model\"] = plsda_best_mod\n",
    "    score[\"plsda_best\"][\"Train Score\"] = accuracy_score(y_train, np.argmax(plsda_mod.predict(X_train_scaled), axis=1) - 1)\n",
    "    score[\"plsda_best\"][\"Validation Score\"] = accuracy_score(y_valid, np.argmax(plsda_mod.predict(X_valid_scaled), axis=1) - 1)\n",
    "    score[\"plsda_best\"][\"Test Score\"] = accuracy_score(y_test, plsda_best_test_pred)\n",
    "    \n",
    "    df_result = pd.DataFrame(score).T\n",
    "    \n",
    "    best_mod = df_result['Validation Score'].astype(float).argmax()\n",
    "    \n",
    "    best_test_score = score[best_mod]['Test Score']\n",
    "    \n",
    "    return df_result, best_mod, best_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['attack_away_defence_home_diff', 'attack_home_defence_away_diff', \n",
    "           'attack_diff', 'defence_diff', 'midfield_diff', 'prestige_diff', 'growth_diff', \n",
    "           'full_age_diff', 'start_age_diff', 'value_euros_millions_diff','wage_euros_thousands_diff', \n",
    "           'goalkeeper_overall_diff', 'bup_dribbling_diff', 'bup_passing_diff', 'bup_speed_diff',\n",
    "           'cc_crossing_diff', 'cc_passing_diff', 'cc_shooting_diff', 'd_aggresion_diff', 'd_pressure_diff', \n",
    "           'd_width_diff', 'gdp_diff', 'is_home', 'raw_gdp_diff', \n",
    "          'score_past_5_games_diff', 'score_conceded_past_5_games_diff']\n",
    "train = train[columns + ['home_win']]\n",
    "test = test[columns + ['Group', 'home_win']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   40.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "# 85 seems like a good seed\n",
    "df, best_mod, best_score = full_models(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Validation Score</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.514832</td>\n",
       "      <td>0.55</td>\n",
       "      <td>LogisticRegressionCV(Cs=10, class_weight=None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.514173</td>\n",
       "      <td>0.542105</td>\n",
       "      <td>LinearDiscriminantAnalysis(n_components=None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.526697</td>\n",
       "      <td>0.444737</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(priors=None, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.523401</td>\n",
       "      <td>0.536842</td>\n",
       "      <td>RandomizedSearchCV(cv=5, error_score='raise-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.59375</td>\n",
       "      <td>0.591958</td>\n",
       "      <td>0.515789</td>\n",
       "      <td>RandomizedSearchCV(cv=5, error_score='raise-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcr_full</th>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.511536</td>\n",
       "      <td>0.534211</td>\n",
       "      <td>LogisticRegressionCV(Cs=10, class_weight=None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcr_80%</th>\n",
       "      <td>0.65625</td>\n",
       "      <td>0.507581</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>LogisticRegressionCV(Cs=10, class_weight=None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcr_90%</th>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.528947</td>\n",
       "      <td>LogisticRegressionCV(Cs=10, class_weight=None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcr_best</th>\n",
       "      <td>0.65625</td>\n",
       "      <td>0.507581</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>LogisticRegressionCV(Cs=10, class_weight=None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plsda_best</th>\n",
       "      <td>0.65625</td>\n",
       "      <td>0.509558</td>\n",
       "      <td>0.536842</td>\n",
       "      <td>PLSRegression(copy=True, max_iter=500, n_compo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Test Score Train Score Validation Score  \\\n",
       "Logistic Regression     0.5625    0.514832             0.55   \n",
       "LDA                   0.609375    0.514173         0.542105   \n",
       "QDA                   0.546875    0.526697         0.444737   \n",
       "Random Forest         0.640625    0.523401         0.536842   \n",
       "XGBoost                0.59375    0.591958         0.515789   \n",
       "pcr_full              0.671875    0.511536         0.534211   \n",
       "pcr_80%                0.65625    0.507581         0.552632   \n",
       "pcr_90%               0.703125    0.512195         0.528947   \n",
       "pcr_best               0.65625    0.507581         0.552632   \n",
       "plsda_best             0.65625    0.509558         0.536842   \n",
       "\n",
       "                                                                 model  \n",
       "Logistic Regression  LogisticRegressionCV(Cs=10, class_weight=None,...  \n",
       "LDA                  LinearDiscriminantAnalysis(n_components=None, ...  \n",
       "QDA                  QuadraticDiscriminantAnalysis(priors=None, reg...  \n",
       "Random Forest        RandomizedSearchCV(cv=5, error_score='raise-de...  \n",
       "XGBoost              RandomizedSearchCV(cv=5, error_score='raise-de...  \n",
       "pcr_full             LogisticRegressionCV(Cs=10, class_weight=None,...  \n",
       "pcr_80%              LogisticRegressionCV(Cs=10, class_weight=None,...  \n",
       "pcr_90%              LogisticRegressionCV(Cs=10, class_weight=None,...  \n",
       "pcr_best             LogisticRegressionCV(Cs=10, class_weight=None,...  \n",
       "plsda_best           PLSRegression(copy=True, max_iter=500, n_compo...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
