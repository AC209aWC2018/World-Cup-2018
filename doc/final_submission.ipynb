{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview and Motivation\n",
    "\n",
    "While soccer is one of the most popular sports in the world, its analytics is lackluster in comparison to other popular sports such as baseball, American football, hockey, and basketball. This is particularly evident for the FIFA World Cup. The amount of analytics done on the FIFA World Cup is just miniscule in comparison to its scale, given that it is one of the most popular and highly televised sporting events in the world! This can be attributed to the general resistance of the sport (or FIFA) towards technology. Even though numerous other sports already use video technology to review plays while on the pitch, FIFA World Cup 2018 was the first time Video Assistant Referee (VAR) was used in a major soccer tournament. \n",
    "\n",
    "![](https://pics.me.me/si-fifa-fortnite-var-room-fifaworld-cup-russia-2018-use-34316423.png)\n",
    "<center>Source: https://pics.me.me/si-fifa-fortnite-var-room-fifaworld-cup-russia-2018-use-34316423.png</center>\n",
    "\n",
    "Another possible explanation is it's uniqueness as a sporting event of a global scale. The only other comparison is the Olympics. As a result, it is just logistically difficult for international teams to play each other very frequently! In fact, soccer clubs are often very resistant to allowing their players leave for international friendlies, especially if it is in the middle of their sporting season. \n",
    "\n",
    "![](https://pbs.twimg.com/media/CREXjPkWIAA1_OG.jpg)\n",
    "<center>Source: https://pbs.twimg.com/media/CREXjPkWIAA1_OG.jpg</center>\n",
    "\n",
    "As countries just do not compete against each other at the highest level frequently, there is a lack of high quality data that can be immediately fed into models to perform predictions. This is one of the biggest limitations on our project. While we would have liked to construct a model based on historical match based statistics, such as the possesion rate, the number of shots on target, etc., these data are just not readily available (free). Most of these statistics for international matches seem to have been calculated only since the start of the 2010s. Even then, only matches at the highest level, during tournaments or featuring top teams, have these statistics available. As such, we rely on a mix of simple match based statistics, and team and individual data from the popular FIFA games for our World Cup predictions.\n",
    "\n",
    "The World Cup is composed of 64 matches in total - 48 matches in group stages and 16 matches in knockout (15 + 1 for third place). We plan to predict the outcome of each of the 64 matches independently instead of predicting which teams proceed in each round. This strategy allows our results to be comparable across models. By framing the problem in this way, we plan to approach this problem as a classification problem. Each game can be treated as a multi-class classification problem, where there are three outcomes: win for the home team (or team 1, indicated with 1), win for the away team (or team 2, indicated with -1), or a draw (indicated with 0). In the knockout rounds, we limit the outcome to: win for the home team (or team 1), win for the away team (or team 2), as draws are not allowed. Note that while we refer to teams as 'home' or 'away', we are merely abusing the terminology to distinguish between teams. There is only one true 'home' team for World Cups. \n",
    "\n",
    "To validate how accurate FIFA rankings are, we aim to use a baseline model that leverages FIFA rankings and some other simple team predictors to predict the World Cup results. We plan to create a more advanced model without relying on FIFA rankings. Instead, our advanced model is based on features that we self collected and engineered. The feature engineering process is a follow up to our initial EDA, where we identified features that could possibly impact match results. Ultimately, our analysis attempts to create a model that can predict the World Cup results as accurately as possible, while offering an insight into the features helpful in soccer analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature Review and Related Works\n",
    "\n",
    "Even though soccer analytics is not a well-established field, there are a number of attempts to model the 2018 World Cup using machine learning techniques.\n",
    "\n",
    "For example, Andreas Groll and his team at the University of Dortmund utilized [Poisson regression, random forest, and ranking methods](https://arxiv.org/abs/1806.03208) to simulate the World Cup 100,000 times. Features that Groll used \"include economic factors such as a country’s GDP and population, FIFA’s ranking of national teams, and the properties of the teams themselves, such as their average age, the number of Champions League players they have, whether they have home advantage, and so on.\" (https://www.technologyreview.com/s/611397/machine-learning-predicts-world-cup-winner/) Through these simulations, Groll's model predicted Spain as the most likely winner of the World Cup followed by Germany. We all know how that turned out...\n",
    "\n",
    "![](https://i.ytimg.com/vi/ITlBUIWlsXQ/maxresdefault.jpg)\n",
    "<center>Source: https://i.ytimg.com/vi/ITlBUIWlsXQ/maxresdefault.jpg</center>\n",
    "\n",
    "Similarly, Gerald Muriuki utilized [logistic regression](https://scotch.io/@itsmuriuki/predicting-fifa-world-cup-2018-using-machine-learning) to simulate the World Cup. Using the historic match dataset as his train set, Muriuki only trained on matches in which both teams are playing in the 2018 World Cup. The only feature he used was one-hot encoding all the teams, essentially representing a team's past performance against the other teams as a feature. The model predicted Brazil as the most likely winner. \n",
    "\n",
    "Finally, Rodrigo Nader utilized [SVM](https://towardsdatascience.com/using-machine-learning-to-simulate-world-cup-matches-959e24d0731) to simulate the World Cup. Nader used ratings (Atk, Mid, Def, ovr) about the teams scraped from Fifa Index to build his model. The model predicted Spain as the most likely winner, defeating Brazil in the finals.\n",
    "\n",
    "As we can see, there were many attempts before the World Cup to predict it, with Spain or Brazil prevailing in most cases. However, we did not find any existing work that modelled World Cup 2018 after it had ended. While this may result in some hindsight bias (which we actively tried to avoid), there is still great value in reflecting back on the actual results of the World Cup. This would not only give us some insights into the actual statistics that matter in determining a soccer match, but also provide us with a model that could possibly be applied to future soccer matches. \n",
    "\n",
    "Moreover, as mentioned previously, we model the World Cup based on individual matches for comparability. This is different from the simulation models done previously, which simulates the World Cup sequentially. Nonetheless, our existing model can be extended to predict matches sequentially, although there is not much value in doing so since World Cup 2018 has ended.  \n",
    "\n",
    "Nonetheless, it is evident that the data we chose to use and the features we chose to engineer were inspired by the related works. We hope to combine the features used individually by these related works to make a model of our own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## European Matches\n",
    "For each match, we compute the average statistics for the different ratings for each team and difference them. Just getting the total value would not unfortunately work due to some rows potentially having uneven number of values missing. We then take the difference in the statistic for the home team and away team. For goal keeping ratings, we will only look at the max of each team since in theory the goal keepers in a match should have the best goal keeper statistics.\n",
    "\n",
    "Now let's see if there are any differences in the distributions of the differences depending on whether the home team lost, won, or tied.\n",
    "\n",
    "![Differences in the distributions](img/eda_mean.png)\n",
    "\n",
    "From looking at the mean, it seems in general the mean value for a difference in rating when the home team wins is the greatest out of the three outcomes while the mean value for the difference in rating when the home team loses is the lowest ouf the three outcomes. This seems consistent with what we believe. However, the mean differences seem a little low for any of these cases, especially since the rating ranges from 0 to 100, so mean differences of such small magnitudes might not be significant. Let’s plot the distributions themselves.\n",
    "\n",
    "\n",
    "![Distributions](img/dist.png)\n",
    "\n",
    "Wow! From looking at the plots the distributions of a difference in rating among the three outcome do not really seem that different.\n",
    "\n",
    "This might be an indication that using individual ratings and aggregating them might not be the way to go. Also, so far efforts to get the individual ratings for the actual World Cup data have been unsuccessful, so this may be a sign to find other set of features to predict the world cup. (Later we will see an attempt of using team statistics)\n",
    "\n",
    "Let us also look at whether previous match results will be good predictors.\n",
    "\n",
    "![Previous matches](img/prev_matches.png)\n",
    "\n",
    "We see a similar pattern as before, where home team winning has the highest mean values and away team winning has the lowest mean values. This time the small magnitudes make sense however since we are only looking up to 5 games back. Let us also plot the distributions.\n",
    "\n",
    "![Distribution of previous matches](img/dist_prev_matches.png)\n",
    "\n",
    "This time it is a bit more obvious that home team winning tends to have higher values. It seems like we can probably calculate some kind of momentum and utilize it as a predictor. We will explore more of this concept later on when we make our advanced model.\n",
    "\n",
    "## Conclusion From Europen Dataset\n",
    "\n",
    "\n",
    "From exploration of the European dataset, we saw that aggregating individual player ratings does not seem to help that much while previous matches seem to help. Thus, we decided to only keep the summary statistics of the team rather than players' individual statistics. We will keep these discoveries in mind as we move on to the SOFIFA datasets.\n",
    "\n",
    "## Further Exploring Other Features\n",
    "\n",
    "![Spearman](img/spear_corr_eda.png)\n",
    "\n",
    "The spearman correlation plot gives us an idea of how well these features correlate with our dependent variable. In other words, the highly correlated features, such as overall difference in ratings should give us a fairly good idea of team 1/home team winning.\n",
    "\n",
    "![Distribution](img/dist_2.png)\n",
    "\n",
    "In fact, from the distribution plot we see that the features, such as overall difference in ratings and goalkeeper rating difference, that can better discriminate win, loss for team 1 are more highly correlated with the win/lose. Similarly, features, such as build up dribbling difference, which have low correlation barely show any difference between distribution of different outcomes.\n",
    "\n",
    "![Box plot](img/boxplot.png)\n",
    "\n",
    "Inspecting one of the highly correlated features closely, we see that when the difference is positive (team 1 has an advantage), the likelihood of winning is much higher whereas when it's negative it's much more likely to lose.\n",
    "\n",
    "![Wage Dist](img/dist_wage.png)\n",
    "\n",
    "However, there are also some features that don't have really high correlation and can still discriminate well the win/lose situations when the difference is large. For instance, for the team wage difference, we see when the difference is large, it is much more likely to win/lose, but there is barely any difference in the middle peaking at 0. This is happening because we imputed missing values with 0 to encode lack of information. In fact, in these cases we have a lot of distributions with a really high peak at 0, causing low correlation. Nonetheless, they can still be useful when we do possess the information.\n",
    "\n",
    "## Exploring PCA\n",
    "\n",
    "Inspecting these distribution of features, we noticed them a large proportion of them are similarly shaped and distributed. Therefore, we considered PCA to perform dimensionality reduction, aggregating similar features.\n",
    "\n",
    "![PCA chart](img/pca_chart.png)\n",
    "![PCA results](img/pca_results.png)\n",
    "\n",
    "## Summary\n",
    "\n",
    "First of all, we notice that PCA helps models like LDA and QDA perhaps because of the independent assumption of components imposed by PCA. On the other hand, the performance for Logistic Regression, Random Forest, XGBoost seem to be slightly hurt by the reduced information from PCA.\n",
    "\n",
    "Nonetheless, we see that the best model is QDA with 9 components from PCA. This probably means that performing dimensionality reduction is probably quite helpful in summarizing the information from the data with similar distributions. We will keep this in mind when picking the final model.\n",
    "\n",
    "## Interpreting PCA\n",
    "\n",
    "![Correlation Circle](img/corr_circle.png)\n",
    "\n",
    "We only highlighted the top 20 predictors with largest correlation magnitude as these are likely to be the more important predictors. \n",
    "\n",
    "`start_age_diff` and `full_age_diff` are naturally correlated, and seem to explain a substantial amount of variation in the data. `growth_diff`, which is on the other side of the correlation circle, seems to explain variation that is almost the opposite of `start_age_diff` and `full_age_diff`. This makes intuitive sense as we would expect younger players to have more room for growth.\n",
    "\n",
    "`attack_away_defence_home_diff` and `rank_diff` also seem to be explain similar variation in the data. The rest of the predictors are all clustered at the 3 o'clock region of the circle, right across the predictors `attack_away_defence_home_diff` and `rank_diff`. This suggests that these predictors explain similar variation in the data and might be correlated.\n",
    "\n",
    "![Overall vs Start Age](img/overall_start_age.png)\n",
    "![Offense vs Defense](img/offense_defense.png)\n",
    "\n",
    "![PCA Plot](img/pca_plot.png)\n",
    "![PCA Table1](img/eda_table_1.png)\n",
    "![PCA Table2](img/eda_table_2.png)\n",
    "\n",
    "We can see that PC1 is greatly influenced by `overall`, `defence`, and `midfield`, while PC2 is greatly influenced by `full_age` (negative), `start_age` (negative), and `growth`. This gives us a good way to think about the 2D representation of our dataset summarized by the first two PCs. Teams with higher PC2s generally have lower ages and thus more potential for growth. They are likely to have lots of young, promising players. Teams with higher PC1s are statistically better all-round teams. \n",
    "\n",
    "While this PCA plot is not a measure of how likely a team will win the World Cup (since PCAs only involve the predictors), it can still give us an intuition into the various World Cup teams. \n",
    "\n",
    "We immediately see that France is probably a strong all-round team that also has young, promising players. Nigeria is probably a below-average team but with young, promising players. Costa Rica is probably a below-average team with older players near their peak. Spain is probably a strong all-round team but with older players near their peak. These largely corroborates what we know about those teams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "Our most basic model would be to just predict the majority class every time. In this case, `home_win` = 1 is the majority class. Doing this \"prediction\" on our train set results in an accuracy of 43.8% while doing this \"prediction\" on our test results in an accuracy of 42.19%. This is pretty decent when we have three classes. Any model we build should be better than this test accuracy of just guessing the majority class.\n",
    "\n",
    "Our baseline model was pretty simple. We utilized the differences in FIFA rankings, offense ratings, defense ratings, midfield ratings, overall ratings, and whether the home team is actually playing at home. We will make a train and validation set out of the original train set. We then fitted the model on several different classification algorithms, using cross-validation to train on the models.\n",
    "\n",
    "![Baseline Model Results](img/baseline_results.png)\n",
    "\n",
    "\n",
    "Ultimately, we selected the model with the highest validation accuracy, which was logistic regression in this case. We then will see how the model performs on the test set. Due to the elimination style during playoffs of the World Cup, there are no draws in these playoff matches. We attempted three different approaches to predicting the outcome of theese playoff matches. \n",
    "\n",
    "The first approach is to predict the outcome at 90 minutes (when a regular game ends so that our train set and test set are more \"similar\" to each other) before accounting for penalty kicks and overtime, allowing the model which trained on the training set to also predict draws in the playoff matches of the World Cup. \n",
    "\n",
    "In the second approach, we will predict the outcome at the end of the match; for a playoff match, if the model predicts a draw as most likely, then we instead predict the second most likely outcome of that match. We call this approach the \"Softmax Approach\". \n",
    "\n",
    "The third approach also attempts to predict the outcome at the end of the match. Instead of just predicting the second most likely outcome for a playoff match, we instead just train another model specifically on past World Cup playoff matches on the final outcome of these matches. We then just use this model to predict the playoff matches while the model trained on the training set will predict the preliminaries match. Since we have limited amount of past World Cup playoff matches (only 24 matches because some of them were removed to accomodate the team ratings dataset), we trained a basic logistic regression model as this model in the baseline model case. We call this approach the \"WC Playoff Model\". \n",
    "\n",
    "![Baseline Test Results](img/baseline_test_results.png)\n",
    "\n",
    "Impressive! The baseline model gave us an indea on what accuracy our more advanced model should hope to achieve. In this case the Softmax approach did better than the WC Playoff Model approach; this might be due to the small training set for the playoff matches, the small number of features, or just pure luck. \n",
    "\n",
    "We did some basic analysis to see what exactly the model is getting wrong by plotting some confusion matrices. \n",
    "\n",
    "![Baseline Confusion Matrices](img/baseline_cm.png)\n",
    "\n",
    "Our model does not predict draws at all. This is a bit concerning, but it makes sense given that from our EDA of these simple features we saw that we really could not distinguish draws from home wins and home losses at all for any of the features. For most of the feature distributions, they were always \"sandwiched\" between the two other distributions. Maybe our more advanced models will be able to better predict draws.\n",
    "\n",
    "We see that across train set and test set, the proportions in each entry of the confusion matrices are approximately the same, which is good. This might be an indication that our train and test sets are approximately similar. \n",
    "\n",
    "While it seems like because the accuracy in predicting home loss and home win in the 90 minutes model are higher than those in the softmax approach, we must remember that the true labels of the former approach and the latter two approaches are different, where all the draws in the playoff matches of the test set became either home losses or wins. As a result, the overall accuracy of the the softmax approach is still higher than the former approach despite having lower home loss and home win accuracies; thus we can only compare the overall accuracies of the former approach with the latter two approaches. We can still compare the home loss and home win accuracies between the latter two approaches though since they are using the same test labels, and we see that while the WC Playoff Model is better at predicting home losses, it is worse in predicting home wins by a larger magnitude, resulting in lower overall accuracy. \n",
    "\n",
    "More importantly, we were curious just how important each feature is, especially the FIFA ranking feature, the one feature we are trying to replace. Feature importance of random forest allows us exactly to do so, and since it has similar performance to logistic regression in the train/validation set, we can utilize it in this case.\n",
    "\n",
    "![Baseline Feature Importance](img/baseline_feature_importance.png)\n",
    "\n",
    "\n",
    "It seems like the FIFA rankings is not that important of a feature! Hopefully we can make a better model than the baseline model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond Baseline\n",
    "\n",
    "## Modeling with Feature Engineered Features\n",
    "\n",
    "### Fitting the Models\n",
    "\n",
    "To begin, let’s just naively use all the features we have feature engineered. Similar to before, we will fit different classification models on our data and select the one with the best validation accuracy.\n",
    "\n",
    "\n",
    "Also, like before, we first check whether the variances across the three outcomes are equal, and they do seem quite equal.\n",
    "\n",
    "![Variances](img/variances.png)\n",
    "\n",
    "We ran Logistic Regression, LDA, QDA, Random Forest, and XGBoost and got the following results: \n",
    "![Model scores](img/model_scores.png)\n",
    "\n",
    "We choose the final model to be the one with the highest validation score, which is LDA in this case\n",
    "\n",
    "Now to predict the test set. Similar to before, we will use three different approaches. For the WC Playoff Model approach, we will still use logistic regression for now.\n",
    "\n",
    "![LDA scores](img/lda_scores.png)\n",
    "\n",
    "Wow! It seems that our model with all the features is a decent improvement to the baseline model for the test set in all three approaches. However, the lower train and validation scores in general is a bit concerning.\n",
    "\n",
    "Like before, random forest seems to perform similarly to the best model, so we will utilize its feature importance again.\n",
    "\n",
    "![Random Forest features](img/RF_features.png)\n",
    "\n",
    "\n",
    "Like before, the ratings of the team are pretty important features. Many of the features we have engineered seem to be decent features as well, which should not be surprising from the EDA. Besides 3 of them, many of the momentum features are near the bottom, and this might be due to the fact that these momentum features are obviously highly correlated with each other, and this may be causing the lower train and validation scores. Many of the features in our feature are highly correlated; we would want to deal with this multicollinearity somehow to see if we can achieve better results.\n",
    "\n",
    "### Stacking\n",
    "We saw that our models in general performed similarly in terms of train/validation. Why not try stacking the models together? We will stack the logistic regression, LDA, QDA, Random Forest, and XGBoost models.\n",
    "\n",
    "We got the following results: <br>\n",
    "Stacking Model Train Score: 0.5662491760052736 <br>\n",
    "Stacking Model Validation Score: 0.5368421052631579 <br>\n",
    "Stacking Model Test Score at 90 mins: 0.609375 <br>\n",
    "Stacking Model Test Score at end (Softmax): 0.625 <br>\n",
    "Stacking Model Test Score at end (WC Playoff Model): 0.640625\n",
    "\n",
    "It seems that stacking in this case did not really help that much. The test accuarcies are quite low, although still higher than those of the baseline model.\n",
    "\n",
    "As mentioned before, we are a bit concerned about the fact that our features are highly correlated, which potentially affects our predictions.\n",
    "\n",
    "### Principal Component Regression\n",
    "\n",
    "Principal Component Analysis (PCA) is a way to reduce the dimensionality of dataset by summarizing the variation in our data into a set of new predictors called principal components. These principal components are linear combinations of our original predictors. By selecting the top few principal components, we are projecting our dataset into the space defined by these components. This means that we are projecting our dataset onto a space of smaller dimensionality. Importantly, this will help us reduce the multicollinearity that might be affecting our predictions. Each principal component is constructed such that they are orthogonal with each other. Nonetheless, we understand that this will limit the interpretability of our coefficients.\n",
    "\n",
    "Principal Component Regression (PCR) is basically using the new predictors of reduced dimensionality in a regression problem. In this problem, we inputed the new principal components into our standard logistic regression. In order to decide the number of principal components to keep, we cross-validated the number of principal components that gives us the best validation accuracy.\n",
    "\n",
    "\n",
    "We got the following results: <br>\n",
    "Best Validation Accuracy Number of Components: 3 <br>\n",
    "PCR (Best) Train Score: 0.5042847725774555 <br>\n",
    "PCR (Best) Validation Score: 0.5473684210526316 <br>\n",
    "PCR (Best) Test Score at 90 mins: 0.5625 <br>\n",
    "PCR (Best) Test Score at end (Softmax): 0.578125 <br>\n",
    "PCR (Best) Test Score at end (WC Playoffs Model): 0.609375\n",
    "\n",
    "![PCR Plot](img/pcr_plot.png)\n",
    "\n",
    "In this case, PCR was not a good option. The test accuracy decreased quite significantly. We may need to take into the account the outcome as well when we reduce the dimension of our feature set.\n",
    "\n",
    "### Partial Least Squares Regression\n",
    "\n",
    "Another way that can help us deal with the issues of multicollinearity in our dataset is Partial Least Squares Regression (PLSR). Similar to PCA, PLSR involves projecting the predictors onto orthogonal components. However, the PLSR components are constructed such that they not only approximate the predictors, but are also well correlated with the response. As such, we assume that both the predictors and the response are functions of (reduced) principal components. In this problem, our response variable is a multi-class categorical variable. As such, we could use the PLS2 algorithm which simultaneously decomposes on the multi-class variable directly. We could also use the PLS1 algorithm on each category in our response variable separately. \n",
    "\n",
    "To demonstrate how the Partial Least Squares algorithms works, we have included a pseudo-code for PLS1:\n",
    "\n",
    "Set $X_0 = X$, and $y_0 = y$\n",
    "\n",
    "for $h = 1, 2, ... r$ do (where r is the dimension of the predictors)\n",
    "\n",
    "$\\hspace{1cm} \\mathbf{w_h} = \\mathbf{X^T_{h-1}y_{h-1}/y^T_{h-1}y_{h-1}}$ (regress predictors $x_j$ on response $y$)\n",
    "\n",
    "$\\hspace{1cm} ||\\mathbf{w_h}|| = 1$ (normalize)\n",
    "\n",
    "$\\hspace{1cm} \\mathbf{z_h} = \\mathbf{X_{h-1}w_h/w^T_hw_h}$ (regress predictors $x_j$ on weights $w_h$)\n",
    "\n",
    "$\\hspace{1cm} \\mathbf{p_h} = \\mathbf{X^T_{h-1}z_h/z^T_hz_h}$ (regress predictors $x_j$ on components $z_h$)\n",
    "\n",
    "$\\hspace{1cm} \\mathbf{X_h} = \\mathbf{X_{h-1} - z_hp^T_h}$ (deflate $X_{h-1}$)\n",
    "\n",
    "$\\hspace{1cm} d_h = \\mathbf{y^T_hz_h/z^T_hz_h}$ (regress response $y_h$ onto components $z_h$)\n",
    "\n",
    "$\\hspace{1cm} \\mathbf{y_h} = \\mathbf{y_{h-1} - d_hz_h}$ (deflate $y_{h-1}$)\n",
    "\n",
    "end for\n",
    "\n",
    "The PLS2 algorithm is just an extension for a multi-dimensional response variable.\n",
    "\n",
    "Importantly, PLS selects components which gives us the greatest reduction in the covariance of our predictors and response. If we represent our components as $\\mathbf{z}$, and the response as $\\mathbf{y}$, it can be shown that PLSR optimizes with respect to the weights $\\mathbf{w}$\n",
    "\n",
    "$$ \\arg\\max_{\\mathbf{w}} cor^2(\\mathbf{y, z})var(\\mathbf{y})var(\\mathbf{z})$$\n",
    "\n",
    "It can thus be seen that PLSR tries to maximize the correlation between the components and the response whilst trying to maximize the variance captured by the components. \n",
    "\n",
    "This not only allows us to resolve the multicollinearity issues through the creation of orthogonal components just as in PCR, but also allows us to create components that are correlated with the response. It is likely that this might perform even better than PCR.\n",
    "\n",
    "\n",
    "We got the following results for PLS1-DA: <br>\n",
    "Best Validation Accuracy Number of Components: 16 <br>\n",
    "PLS1-DA (Best) Train Score: 0.5227422544495716<br>\n",
    "PLS1-DA (Best) Validation Score: 0.5552631578947368<br>\n",
    "\n",
    "\n",
    "![PLS 1](img/pls-da1.png)\n",
    "\n",
    "We got the following results for PLS2-DA: <br>\n",
    "Best Validation Accuracy Number of Components: 9 <br>\n",
    "PLS2-DA (Best) Train Score: 0.5181278839815425 <br>\n",
    "PLS2-DA (Best) Validation Score: 0.5526315789473685 <br>\n",
    "\n",
    "![PLS 1](img/pls-da2.png)\n",
    "In the case of binary labels, PLS1-DA and PLS2-DA are the same, so we will look at the third approach in PLS2-DA.\n",
    "\n",
    "PLS1-DA (Best) Test Score at 90 mins: 0.640625 <br>\n",
    "PLS1-DA (Best) Test Score at end (Softmax): 0.6875 <br>\n",
    "PLS2-DA (Best) Test Score at 90 mins: 0.59375<br>\n",
    "PLS2-DA (Best) Test Score at end (Softmax): 0.625<br>\n",
    "PLS1-DA/PLS2-DA (Best) Test Score at end (WC Playoffs Model): 0.65625<br>\n",
    "\n",
    "Compared to the full model, we do not see much change in the PLS1-DA model on the test set while we see a decrease in performance of PLS2-DA on the test set, although PLS1-DA does perform better in the second approach than the full model does; thus PLS1-DA is the best model we have seen so far! What's more important is that the validation scores for PLS1-DA were higher than those in the full model. It is likely that multicollinearity was causing the decrease in our validation scores.\n",
    "\n",
    "Now, suppose we don't actually know anything about the test set. Which model would we have actually chosen? Like before, we can only look at the validation scores.\n",
    "\n",
    "![Final models](img/final_models.png)\n",
    "\n",
    "Based on validation scores, we would have chosen PLS1-DA, the best model!\n",
    "\n",
    "Let's see the confusion matrices for our best model, PLS1-DA.\n",
    "\n",
    "![Confusion Matrix](img/conf.png)\n",
    "\n",
    "The model is actually predicting some draws now for the training set and test set, although still very little. As mentioned before, it is just very hard to predict draws, but this is definitely an improvement compared to the baseline model.\n",
    "\n",
    "Compared to the baseline model, it seems that the model is better in predicting when \"home\" team loses in the test set in all three approaches. This might be due to some bias of how we feature engineer. Since none of us really were experts in soccer, we chose features that we observed from the World Cup alone, so these features might be biased toward the test set.\n",
    "\n",
    "The Softmax approach had higher home loss and home win accuracies than the WC Playoff Model approach; this might be due to the small training set for the playoff matches, so we could just be overfitting to the traing set. As mentioned in the baseline model, we cannot really compare the confusion matrices of the three approaches to the test set, as the true labels between the 90 minutes approach are different from those than the true labels in the other two approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Neural Network on Small Training Set\n",
    "\n",
    "Out of plain curiosity, we wondered how a simple neural network would perform on our problem (Everyone wants to try deep learning nowadays). Because our training set is so small, we do not believe that the neural network will outperform any of our models from the previous part. In fact, it might overfit to the training set and perform worse than our other models. This notebook is just to experiment around with neural networks and see its performance on a small dataset. We will only look at the outcome at 90 minutes and Softmax in the test set, since it would be pretty complicated to come up with a scheme for the WC Playoff Model configuration, especially since there are so few WC playoff matches in our dataset.\n",
    "\n",
    "Our simple neural network had a total of 3 hidden node layers, with 15 nodes in each layer. We added regularization on each layer and also add drop out layers to try to prevent overfitting.\n",
    "\n",
    "![Neural Net Design](img/neural_net_design.png)\n",
    "\n",
    "\n",
    "![Neural Net Results](img/neural_net_results.png)\n",
    "\n",
    "\n",
    "Surprisngly, the neural network actually did better than we thought it would. This most likely stems from the regularization we added as well as the dropout layers. However, the neural network stilldid not perform as well as our best model.\n",
    "\n",
    "We have thus shown that neural networks do not really help improve accuracy in this small dataset; it shows that we do not really need that complex of a model in this problem.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Future Work\n",
    "\n",
    "In this project we explored the idea of predicting the 2018 World Cup through a data science approach. We collected data related to matches, team ratings, and FIFA rankings. We use as our training set the matches played by national teams starting from 2006. However, due to limitations of the team ratings dataset, we had to get rid of many matches when merging with the matches dataset with the team ratings dataset. The training set has three outcomes, home team loses, draw, and home team wins. Although the dataset designates one team as home team, in most cases this does not mean anything and one can switch home team and away team. As a result, any feature we use will have to be symmetric in nature. \n",
    "\n",
    "Due to the elimination style during playoffs of the World Cup, there are no draws in these playoff matches. We attempted different approaches to predicting the outcome of these playoff matches. The first approach is to predict the outcome at 90 minutes (when a regular game ends so that our train set and test set are more \"similar\" to each other) before accounting for penalty kicks and overtime, allowing the model which trained on the training set to also predict draws in the playoff matches of the World Cup. In the second approach, we predicted the outcome at the end of the match; for a playoff match, if the model predicts a draw as most likely, then we instead predict the second most likely outcome of that match. The third approach also attempts to predict the outcome at the end of the match. Instead of just predicting the second most likely outcome for a playoff match, we instead just train another model specifically on past World Cup playoff matches on the final outcome of these matches; we then just use this model to predict the playoff matches while the model trained on the training set will predict the preliminaries match. \n",
    "\n",
    "We wanted to see just how reliable FIFA rankings are in determining the outcome of a match, so we built a baseline model consisting of just FIFA rankings, attack ratings, defense ratings, midfield ratings, and overall ratings of the teams. We tried out a variety of classification methods such as logistic regression, linear discriminant analysis, quadratic discriminant analysis, random forest, and XGBoost, using cross-validation to train on the models and ultimately selecting the model with the highest validation accuracy. With this model, we achieved decent predictions on the 2018 World Cup. Also, with the baseline model, we realized that FIFA rankings do not have that much of an impact on the outcome of the matches, indicating that a model without FIFA rankings can achieve better results than the baseline model if we feature engineer good features.\n",
    "\n",
    "Through reviewing past works and exploratory data analysis, we realized that features related to other aspects of the team not captured by the baseline model, such as the income, age, and more specific statistics of the players of the team than just one rating on attack, one rating on defense, etc. (such as dribbling skills, passing skills, etc.), or momentum in the past few games, matter. Furthermore, not surprisingly the wealth of the country matters as well, in which we compared the GDP of countries on the same continent, acting as a proxy for comparing GDP of teams in the same confederation.\n",
    "\n",
    "Similar to the baseline model, we first tried a variety of classification methods and use cross-validation to train them, selecting the model with the highest validation accuracy as the model of use. With this model, we achieved impressive increases to our test accuracies. We then tried stacking, but that did not result in anything significant. Due to the multicollineariy nature of our features, we utilized the dimension reduction techniques to conduct Principal Component Regression and Partial Least Squares Discriminant Analysis. In the end we saw that Partial Least Squares Discriminant Analysis was comparable to the full model, and better in the case of the second approach. \n",
    "\n",
    "![Model Results](img/model_results.png)\n",
    "\n",
    "We also tried out a simple neural network just for educational purposes, and while it performed better than the baseline model, it did not really perform as well as the more advanced models, which is not surprising due to our small training set. \n",
    "\n",
    "As shown, the models we built have already shown decent results, but of course there is always room for improvement. The immediate next step to take is to think of more complex features. We would also like to explore the impact of individual players on the match; while team ratings may capture an aggregate view of the players, we would like to be even more granular to see if individual players can \"carry\" their teams. We had attempted to do so during the beginning of this project, but one of the main constraints that we encountered was that it was basically impossible to match individual players on the national stage. We believe that this problem would become resolved as the field becomes more developed and centralized; eventually a website or database like https://www.baseball-reference.com/ will be built, but for soccer. In applying data science to any field, we believe that domain knowledge about the field is the most necessary requirement to improve the model. As such, another crucial next step would be acquire domain knowledge to recognize what makes a team \"good\" considering that none of us basically have any knowledge about soccer at all. \n",
    "\n",
    "This project proves that there is a lot of potential for the field to expand. There is no doubt in the future we will see teams rely heavily on analytics to make decision, just like how baseball, basketball and American football do in the current era. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
